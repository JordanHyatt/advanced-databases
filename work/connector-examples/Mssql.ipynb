{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186de43b-7642-4217-be35-684874c6f61c",
   "metadata": {},
   "source": [
    "# Example to Read / Write to Microsoft SQL Server with Spark\n",
    "\n",
    "Generic JDBC Documentation: https://spark.apache.org/docs/3.1.2/sql-data-sources-jdbc.html\n",
    "\n",
    "This approach should be similar for any JDBC database.\n",
    "\n",
    "## mssql-cli \n",
    "\n",
    "This non-spark tool allows you to manage the database from the CLI. We use it here to create a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4622be4-c717-4e37-818a-dcf339d7d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq mssql-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76010458-b041-4c75-a5af-4b9461b31d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!mssql-cli -S mssql -U sa -P SU2Orange! -Q \"CREATE DATABASE TEST\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981fe08-2743-45a0-a1fe-8878ff5f87d7",
   "metadata": {},
   "source": [
    "## Spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6ec98d-1d75-4f77-a899-144ce7e3e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a2a9a3-6e79-44c9-a7d7-a9ebf297275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jdbc:sqlserver://mssql:1433;databaseName=master;user=sa;password=SU2Orange!;authentication=SqlPassword;encrypt=true;trustServerCertificate=true\n"
     ]
    }
   ],
   "source": [
    "# SQLSERVRER CONFIGURATION\n",
    "server = \"mssql\"\n",
    "server_str = f\"jdbc:sqlserver://{server}:1433\"\n",
    "database_name = \"master\" \n",
    "username = \"sa\"\n",
    "password = \"SU2Orange!\" \n",
    "url = f\"{server_str};databaseName={database_name};user={username};password={password};authentication=SqlPassword;encrypt=true;trustServerCertificate=true\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a6e22e-429d-47e2-ba58-4f336d0336a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "com.microsoft.sqlserver#mssql-jdbc added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ce67ad77-9e87-4e2d-87b7-3fa4696b79f1;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.microsoft.sqlserver#mssql-jdbc;9.4.1.jre11 in central\n",
      ":: resolution report :: resolve 111ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tcom.microsoft.sqlserver#mssql-jdbc;9.4.1.jre11 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ce67ad77-9e87-4e2d-87b7-3fa4696b79f1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/6ms)\n",
      "22/01/07 17:46:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/07 17:46:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Spark init\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "      .config(\"spark.jars.packages\",\"com.microsoft.sqlserver:mssql-jdbc:9.4.1.jre11\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff89a7f1-17a3-4051-82c8-1a430913bae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.82</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3098.12</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251.11</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1725.05</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.39</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212.55</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.00</td>\n",
       "      <td>NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>497.00</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>823.80</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.11</td>\n",
       "      <td>TWTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price symbol\n",
       "0   126.82   AAPL\n",
       "1  3098.12   AMZN\n",
       "2   251.11     FB\n",
       "3  1725.05   GOOG\n",
       "4   128.39    IBM\n",
       "5   212.55   MSFT\n",
       "6    78.00    NET\n",
       "7   497.00   NFLX\n",
       "8   823.80   TSLA\n",
       "9    45.11   TWTR"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read local data\n",
    "df = spark.read.option(\"multiline\",\"true\").json(\"/home/jovyan/datasets/json-samples/stocks.json\")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb79fd-f8d9-41ea-9a91-956f2a25a5ec",
   "metadata": {},
   "source": [
    "## Writing Data\n",
    "\n",
    "- In spark Overwrite mode, the table will be re-created each time.\n",
    "- Because there is no SQL, a table key cannot be specified without using a custom schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fc4513b-4d4b-4ccc-b943-dd249d64ee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- price: double (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write create the table, inferring a schema on write:\n",
    "tablename = \"stocks\"\n",
    "df.write.format(\"jdbc\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", tablename) \\\n",
    "    .save()\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208a97c-635a-4a39-b5e2-cdecd7421640",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "- Reading data back out can be done with a SELECT statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66dfeead-c71c-4a6e-979b-ed78af9e71d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.0</td>\n",
       "      <td>NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>497.0</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price symbol\n",
       "0   78.0    NET\n",
       "1  497.0   NFLX"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read by query\n",
    "sql = \"select * from stocks where symbol like 'N%'\"\n",
    "stocks = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"query\", sql) \\\n",
    "    .load()\n",
    "    \n",
    "stocks.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7146670-66b5-4b07-b9f9-482666637928",
   "metadata": {},
   "source": [
    "## Writing data to an existing table\n",
    "\n",
    "- use spark's \"append\" modifier to write the data.\n",
    "- in typical SQL fashion, constraint failures will cause the write to rollback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "746eb138-d4c5-4ffd-9860-e16129b0aeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GME</td>\n",
       "      <td>136.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol   price\n",
       "0    GME  136.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can add a stock with append mode\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "data = [(\"GME\", 136.34)]\n",
    "schema = StructType([\\\n",
    "    StructField(\"symbol\",StringType(),nullable=True), \\\n",
    "    StructField(\"price\",DoubleType(),nullable=True), \\\n",
    "    ])\n",
    "                     \n",
    "newstock = spark.createDataFrame(data=data,schema=schema)\n",
    "\n",
    "newstock.write.format(\"jdbc\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", \"stocks\") \\\n",
    "    .save()\n",
    "\n",
    "newstock.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff41f61b-1772-4829-bcfa-a363ebc71733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1725.05</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.34</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price symbol\n",
       "0  1725.05   GOOG\n",
       "1   136.34    GME"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the new stock added\n",
    "sql = \"select * from stocks where symbol like 'G%'\"\n",
    "stocks = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"query\", sql) \\\n",
    "    .load()\n",
    "stocks.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa731b-13a9-4c61-840b-b396e5741992",
   "metadata": {},
   "source": [
    "## Executing Arbitrary SQL \n",
    "\n",
    "- Spark / JDBC is not appropriate for executing DDL or DML commands like CREATE TABLE or UPDATE\n",
    "- Instead use a non-big data tool, like your typical SQL client.\n",
    "- You can use `mssql-cli` as demonstrated above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a6b8dd7-afc2-4279-ba2d-6d1e4a610c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Commands completed successfully.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truncate the table\n",
    "!!mssql-cli -S mssql -U sa -P SU2Orange! -Q \"TRUNCATE TABLE stocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f009799-e6ed-4ec7-97e6-a464d1294fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
